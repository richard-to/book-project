{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Amazon salesrank data books analysis\n",
    "\n",
    "This notebook performs some exploratory analysis on the [Amazon sales rank data for print and kindle books dataset](https://www.kaggle.com/ucffool/amazon-sales-rank-data-for-print-and-kindle-books) found on Kaggle.\n",
    "\n",
    "This notebook just looks at the amazon_com_extras.csv table which looks like a lookup table for based on ASIN."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Set up and load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructField, StructType\n",
    "from pyspark_dist_explore import hist\n",
    "\n",
    "import helpers as H\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ExploreAmazonBooks\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "AMZ_BOOKS_PATH = os.getenv(\"AMZ_BOOKS_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_df = spark.read.option(\"header\", \"true\").csv(AMZ_BOOKS_PATH)"
   ]
  },
  {
   "source": [
    "## Inspect table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         ASIN GROUP     FORMAT  \\\n",
       "0  1250150183  book  hardcover   \n",
       "1  0778319997  book  hardcover   \n",
       "2  1608322564  book  hardcover   \n",
       "3  0310325331  book  hardcover   \n",
       "4  0312616295  book  hardcover   \n",
       "\n",
       "                                               TITLE  \\\n",
       "0  The Swamp: Washington's Murky Pool of Corrupti...   \n",
       "1            Rise and Shine, Benedict Stone: A Novel   \n",
       "2  Sell or Be Sold: How to Get Your Way in Busine...   \n",
       "3  Christian Apologetics: An Anthology of Primary...   \n",
       "4  Gravity: How the Weakest Force in the Universe...   \n",
       "\n",
       "                               AUTHOR                   PUBLISHER  \n",
       "0                        Eric Bolling          St. Martin's Press  \n",
       "1                     Phaedra Patrick              Park Row Books  \n",
       "2                       Grant Cardone  Greenleaf Book Group Press  \n",
       "3  Khaldoun A. Sweis, Chad V. Meister                   Zondervan  \n",
       "4                         Brian Clegg          St. Martin's Press  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ASIN</th>\n      <th>GROUP</th>\n      <th>FORMAT</th>\n      <th>TITLE</th>\n      <th>AUTHOR</th>\n      <th>PUBLISHER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1250150183</td>\n      <td>book</td>\n      <td>hardcover</td>\n      <td>The Swamp: Washington's Murky Pool of Corrupti...</td>\n      <td>Eric Bolling</td>\n      <td>St. Martin's Press</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0778319997</td>\n      <td>book</td>\n      <td>hardcover</td>\n      <td>Rise and Shine, Benedict Stone: A Novel</td>\n      <td>Phaedra Patrick</td>\n      <td>Park Row Books</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1608322564</td>\n      <td>book</td>\n      <td>hardcover</td>\n      <td>Sell or Be Sold: How to Get Your Way in Busine...</td>\n      <td>Grant Cardone</td>\n      <td>Greenleaf Book Group Press</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0310325331</td>\n      <td>book</td>\n      <td>hardcover</td>\n      <td>Christian Apologetics: An Anthology of Primary...</td>\n      <td>Khaldoun A. Sweis, Chad V. Meister</td>\n      <td>Zondervan</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0312616295</td>\n      <td>book</td>\n      <td>hardcover</td>\n      <td>Gravity: How the Weakest Force in the Universe...</td>\n      <td>Brian Clegg</td>\n      <td>St. Martin's Press</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "amz_df.limit(5).toPandas().head()"
   ]
  },
  {
   "source": [
    "## ASIN\n",
    "\n",
    "- Some invalid ASINs\n",
    "- How many ISBNS?\n",
    "- About half our ISBNS (doesn't seem to have ISBN13s)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+--------------------+\n",
      "|count(ASIN)|count(DISTINCT ASIN)|\n",
      "+-----------+--------------------+\n",
      "|      63755|               63750|\n",
      "+-----------+--------------------+\n",
      "\n",
      "+---------------+\n",
      "|Has Null (ASIN)|\n",
      "+---------------+\n",
      "|              0|\n",
      "+---------------+\n",
      "\n",
      "+----------+------------+\n",
      "|      ASIN|length(ASIN)|\n",
      "+----------+------------+\n",
      "|         \"|           1|\n",
      "|        L\"|           2|\n",
      "|       M.\"|           3|\n",
      "|B07C8H79J2|          10|\n",
      "|B07C5NLH68|          10|\n",
      "|B0032AMDIW|          10|\n",
      "|B00P86KQX2|          10|\n",
      "|B0145038EA|          10|\n",
      "|B07CB569MB|          10|\n",
      "|B0080OYR52|          10|\n",
      "+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+------------+\n",
      "|                ASIN|length(ASIN)|\n",
      "+--------------------+------------+\n",
      "|\t\t\t - Classics Il...|          43|\n",
      "|\t\t\t - Classics Il...|          41|\n",
      "|\",\"Stichting Kuns...|          29|\n",
      "|* Avoiding a Big ...|          24|\n",
      "|* Talking With th...|          24|\n",
      "|* Finding Lasting...|          23|\n",
      "|          B0145038EA|          10|\n",
      "|          B07CB569MB|          10|\n",
      "|          B0032AMDIW|          10|\n",
      "|          B0080OYR52|          10|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.ASIN)\n",
    "H.check_nulls(amz_df, amz_df.ASIN, amz_df.TITLE)\n",
    "H.check_lengths(amz_df, amz_df.ASIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n",
      "|                ASIN|\n",
      "+--------------------+\n",
      "|\t\t\t - Classics Il...|\n",
      "|\t\t\t - Classics Il...|\n",
      "|                   \"|\n",
      "|\",\"Stichting Kuns...|\n",
      "|* Avoiding a Big ...|\n",
      "|* Finding Lasting...|\n",
      "|* Talking With th...|\n",
      "|          0002247399|\n",
      "|          0006276482|\n",
      "|          0006391702|\n",
      "|          0006513379|\n",
      "|          0007116985|\n",
      "|          0007177771|\n",
      "|          0007184700|\n",
      "|          0007189885|\n",
      "|          0007204493|\n",
      "|          000721393X|\n",
      "|          0007224885|\n",
      "|          0007230206|\n",
      "|          0007232241|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+\n",
      "|count(ASIN)|\n",
      "+-----------+\n",
      "|      33532|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    amz_df\n",
    "    .select(amz_df.ASIN)\n",
    "    .distinct()\n",
    "    .filter(amz_df.ASIN.startswith(\"B\") == False)\n",
    "    .sort(amz_df.ASIN.asc()).show()\n",
    ")\n",
    "(\n",
    "    amz_df\n",
    "    .filter(amz_df.ASIN.startswith(\"B\") == False)\n",
    "    .agg(F.count(amz_df.ASIN)).show()\n",
    ")"
   ]
  },
  {
   "source": [
    "## GROUP\n",
    "\n",
    "- A few nulls\n",
    "- Some strange groups"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------+---------------------+\n",
      "|count(GROUP)|count(DISTINCT GROUP)|\n",
      "+------------+---------------------+\n",
      "|       63751|                    7|\n",
      "+------------+---------------------+\n",
      "\n",
      "+----------------+\n",
      "|Has Null (GROUP)|\n",
      "+----------------+\n",
      "|               4|\n",
      "+----------------+\n",
      "\n",
      "+-----------------+\n",
      "|Has Empty (GROUP)|\n",
      "+-----------------+\n",
      "|                0|\n",
      "+-----------------+\n",
      "\n",
      "+-----+-------------+\n",
      "|GROUP|length(GROUP)|\n",
      "+-----+-------------+\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| book|            4|\n",
      "| book|            4|\n",
      "| book|            4|\n",
      "| book|            4|\n",
      "| book|            4|\n",
      "| book|            4|\n",
      "+-----+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+-------------+\n",
      "|               GROUP|length(GROUP)|\n",
      "+--------------------+-------------+\n",
      "|Albert Lewis Kant...|           42|\n",
      "|Lorenz Graham, Jr...|           36|\n",
      "|Ron L. Deal, Denn...|           26|\n",
      "|Paul H Brookes Pu...|           21|\n",
      "|   Stuart Bauer M.D.|           18|\n",
      "|              kindle|            6|\n",
      "|              kindle|            6|\n",
      "|              kindle|            6|\n",
      "|              kindle|            6|\n",
      "|              kindle|            6|\n",
      "+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.GROUP)\n",
    "H.check_nulls(amz_df, amz_df.GROUP, amz_df.ASIN)\n",
    "H.check_empty_strings(amz_df, amz_df.GROUP)\n",
    "H.check_lengths(amz_df, amz_df.GROUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|               GROUP|\n+--------------------+\n|              kindle|\n|                book|\n|Ron L. Deal, Denn...|\n|Paul H Brookes Pu...|\n|Lorenz Graham, Jr...|\n|Albert Lewis Kant...|\n|   Stuart Bauer M.D.|\n|                null|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    amz_df\n",
    "    .select(amz_df.GROUP)\n",
    "    .distinct()\n",
    "    .sort(amz_df.GROUP.desc()).show()\n",
    ")"
   ]
  },
  {
   "source": [
    "## FORMAT\n",
    "\n",
    "- A few nulls"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+----------------------+\n",
      "|count(FORMAT)|count(DISTINCT FORMAT)|\n",
      "+-------------+----------------------+\n",
      "|        63750|                     7|\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-----------------+\n",
      "|Has Null (FORMAT)|\n",
      "+-----------------+\n",
      "|                5|\n",
      "+-----------------+\n",
      "\n",
      "+------------------+\n",
      "|Has Empty (FORMAT)|\n",
      "+------------------+\n",
      "|                 0|\n",
      "+------------------+\n",
      "\n",
      "+---------+--------------+\n",
      "|   FORMAT|length(FORMAT)|\n",
      "+---------+--------------+\n",
      "|     null|          null|\n",
      "|     null|          null|\n",
      "|     null|          null|\n",
      "|     null|          null|\n",
      "|     null|          null|\n",
      "|hardcover|             9|\n",
      "|hardcover|             9|\n",
      "|hardcover|             9|\n",
      "|hardcover|             9|\n",
      "|hardcover|             9|\n",
      "+---------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+--------------+\n",
      "|              FORMAT|length(FORMAT)|\n",
      "+--------------------+--------------+\n",
      "|Bethany House Pub...|            24|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "|mass market paper...|            21|\n",
      "+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.FORMAT)\n",
    "H.check_nulls(amz_df, amz_df.FORMAT, amz_df.ASIN)\n",
    "H.check_empty_strings(amz_df, amz_df.FORMAT)\n",
    "H.check_lengths(amz_df, amz_df.FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|              FORMAT|\n+--------------------+\n|           paperback|\n|mass market paper...|\n|      kindle edition|\n|           hardcover|\n|Classics Illustrated|\n|Bethany House Pub...|\n|  Joan Beasley Ph.D.|\n|                null|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    amz_df\n",
    "    .select(amz_df.FORMAT)\n",
    "    .distinct()\n",
    "    .sort(amz_df.FORMAT.desc()).show()\n",
    ")"
   ]
  },
  {
   "source": [
    "## TITLE\n",
    "\n",
    "- Some duplicate titles different ASIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------+---------------------+\n",
      "|count(TITLE)|count(DISTINCT TITLE)|\n",
      "+------------+---------------------+\n",
      "|       63747|                58283|\n",
      "+------------+---------------------+\n",
      "\n",
      "+----------------+\n",
      "|Has Null (TITLE)|\n",
      "+----------------+\n",
      "|               8|\n",
      "+----------------+\n",
      "\n",
      "+-----------------+\n",
      "|Has Empty (TITLE)|\n",
      "+-----------------+\n",
      "|                0|\n",
      "+-----------------+\n",
      "\n",
      "+-----+-------------+\n",
      "|TITLE|length(TITLE)|\n",
      "+-----+-------------+\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "| null|         null|\n",
      "|   Es|            2|\n",
      "|   It|            2|\n",
      "+-----+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+-------------+\n",
      "|               TITLE|length(TITLE)|\n",
      "+--------------------+-------------+\n",
      "|Vampire Diaries C...|          249|\n",
      "|NEW VOICES: A MYS...|          243|\n",
      "|The Power of Posi...|          222|\n",
      "|Eiweiß Diät - Sch...|          221|\n",
      "|Jack's Wagers (A ...|          205|\n",
      "|Airbnb Super-Host...|          205|\n",
      "|Paranormal Eyewit...|          205|\n",
      "|How To Analyze Pe...|          204|\n",
      "|50 Gothic Masterp...|          204|\n",
      "|The Complete Illu...|          204|\n",
      "+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.TITLE)\n",
    "H.check_nulls(amz_df, amz_df.TITLE, amz_df.ASIN)\n",
    "H.check_empty_strings(amz_df, amz_df.TITLE)\n",
    "H.check_lengths(amz_df, amz_df.TITLE)"
   ]
  },
  {
   "source": [
    "## AUTHOR\n",
    "\n",
    "- Has nulls\n",
    "- Has duplicates\n",
    "- Has multiple authors listed. Separated by comma it seems\n",
    "- Maxes out at a length of 255 (VARCHAR limit?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+----------------------+\n",
      "|count(AUTHOR)|count(DISTINCT AUTHOR)|\n",
      "+-------------+----------------------+\n",
      "|        63672|                 34211|\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-----------------+\n",
      "|Has Null (AUTHOR)|\n",
      "+-----------------+\n",
      "|               83|\n",
      "+-----------------+\n",
      "\n",
      "+------------------+\n",
      "|Has Empty (AUTHOR)|\n",
      "+------------------+\n",
      "|                 0|\n",
      "+------------------+\n",
      "\n",
      "+------+--------------+\n",
      "|AUTHOR|length(AUTHOR)|\n",
      "+------+--------------+\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "|  null|          null|\n",
      "+------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+--------------+\n",
      "|              AUTHOR|length(AUTHOR)|\n",
      "+--------------------+--------------+\n",
      "|J. Callicott, Mic...|           255|\n",
      "|Julie Taylor, Mar...|           255|\n",
      "|Rhonda Parrish, S...|           255|\n",
      "|Golden Deer Class...|           255|\n",
      "|Martin T. Ingham,...|           255|\n",
      "|L. Ron Hubbard, B...|           255|\n",
      "|Doug Serven, Carl...|           255|\n",
      "|Leanne Banks, Mim...|           255|\n",
      "|Digital Fiction, ...|           255|\n",
      "|Jonathan Maberry,...|           255|\n",
      "+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.AUTHOR)\n",
    "H.check_nulls(amz_df, amz_df.AUTHOR, amz_df.ASIN)\n",
    "H.check_empty_strings(amz_df, amz_df.AUTHOR)\n",
    "H.check_lengths(amz_df, amz_df.AUTHOR)"
   ]
  },
  {
   "source": [
    "## PUBLISHER\n",
    "\n",
    "- Has nulls\n",
    "- Possible duplicates due to different spelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------+-------------------------+\n",
      "|count(PUBLISHER)|count(DISTINCT PUBLISHER)|\n",
      "+----------------+-------------------------+\n",
      "|           57263|                     9060|\n",
      "+----------------+-------------------------+\n",
      "\n",
      "+--------------------+\n",
      "|Has Null (PUBLISHER)|\n",
      "+--------------------+\n",
      "|                6492|\n",
      "+--------------------+\n",
      "\n",
      "+---------------------+\n",
      "|Has Empty (PUBLISHER)|\n",
      "+---------------------+\n",
      "|                    0|\n",
      "+---------------------+\n",
      "\n",
      "+---------+-----------------+\n",
      "|PUBLISHER|length(PUBLISHER)|\n",
      "+---------+-----------------+\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "|     null|             null|\n",
      "+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+-----------------+\n",
      "|           PUBLISHER|length(PUBLISHER)|\n",
      "+--------------------+-----------------+\n",
      "| Cheaper\" in the ...|               95|\n",
      "|Harvard Business ...|               72|\n",
      "|\" and Clausewitz'...|               68|\n",
      "|Digital Horror Fi...|               50|\n",
      "|Resource Publicat...|               50|\n",
      "|Escape Publishing...|               50|\n",
      "|Digital Science F...|               50|\n",
      "|Pelican Ventures ...|               50|\n",
      "|Escape Publishing...|               50|\n",
      "|Digital Science F...|               50|\n",
      "+--------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.PUBLISHER)\n",
    "H.check_nulls(amz_df, amz_df.PUBLISHER, amz_df.ASIN)\n",
    "H.check_empty_strings(amz_df, amz_df.PUBLISHER)\n",
    "H.check_lengths(amz_df, amz_df.PUBLISHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|           PUBLISHER|\n+--------------------+\n|          SCHOLASTIC|\n|SCHOTT MUSIK INTL...|\n|  Schandtaten Verlag|\n|      Schardt Verlag|\n|          Schattauer|\n|            Schiffer|\n|        Schiffer LTD|\n|Schiffer Military...|\n|    Schiffer Pub Ltd|\n| Schiffer Publishing|\n|Schiffer Publishi...|\n|Schiffer Publishi...|\n|     Schirner Verlag|\n|Schmidt Hermann V...|\n|            Schocken|\n|   Schoeffling + Co.|\n|Schoenhofsforeign...|\n|Schoeningh Verlag Im|\n|     Scholars' Press|\n|          Scholastic|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    amz_df\n",
    "    .select(amz_df.PUBLISHER)\n",
    "    .distinct()\n",
    "    .filter(F.lower(amz_df.PUBLISHER).startswith(\"sch\"))\n",
    "    .sort(amz_df.PUBLISHER.asc()).show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
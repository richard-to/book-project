{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Amazon salesrank data books analysis\n",
    "\n",
    "This notebook performs some exploratory analysis on the [Amazon sales rank data for print and kindle books dataset](https://www.kaggle.com/ucffool/amazon-sales-rank-data-for-print-and-kindle-books) found on Kaggle.\n",
    "\n",
    "This notebook just looks at the the salesrank data which is partitioned by ASIN. Inside each file is a JSON object with unix timestamp keys and the values are the salesranks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Set up and load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructField, StructType\n",
    "from pyspark_dist_explore import hist\n",
    "\n",
    "import helpers as H\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AMZ_SALESRANK_000724519X_PATH = os.getenv(\"AMZ_SALESRANK_000724519X_PATH\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ExploreAmazonBooks\").getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transpose_data(data):\n",
    "    json_data = json.loads(data)\n",
    "    return sorted([(timestamp, sales_rank) for timestamp, sales_rank in json_data.items()])\n",
    "amz_rdd = sc.wholeTextFiles(AMZ_SALESRANK_000724519X_PATH).values().flatMap(transpose_data)\n",
    "amz_df = spark.createDataFrame(amz_rdd).toDF(\"timestamp\", \"sales_rank\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+----------+\n|          timestamp|sales_rank|\n+-------------------+----------+\n|2017-10-30 09:07:50|    327588|\n|2017-10-30 11:41:41|    348041|\n|2017-10-30 13:30:42|    353297|\n|2017-10-30 16:22:01|    369732|\n|2017-10-30 17:19:56|    373189|\n|2017-10-30 19:11:45|    386346|\n|2017-10-30 19:49:16|     99600|\n|2017-10-30 22:54:03|    135141|\n|2017-10-30 23:48:52|    155116|\n|2017-10-31 02:23:40|    160114|\n|2017-10-31 03:14:06|    165424|\n|2017-10-31 05:23:58|    166173|\n|2017-10-31 06:04:41|    170119|\n|2017-10-31 07:56:18|    173354|\n|2017-10-31 09:50:45|    188661|\n|2017-10-31 11:53:39|    224768|\n|2017-10-31 14:05:50|    237030|\n|2017-10-31 15:52:22|    262014|\n|2017-10-31 17:35:11|     85465|\n|2017-10-31 18:28:25|     99272|\n+-------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "amz_df = amz_df.withColumn(\"timestamp\", F.from_unixtime(\"timestamp\"))\n",
    "amz_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------+-------------------------+\n",
      "|count(timestamp)|count(DISTINCT timestamp)|\n",
      "+----------------+-------------------------+\n",
      "|            3236|                     3236|\n",
      "+----------------+-------------------------+\n",
      "\n",
      "+--------------------+\n",
      "|Has Null (timestamp)|\n",
      "+--------------------+\n",
      "|                   0|\n",
      "+--------------------+\n",
      "\n",
      "+----------------+--------------+-------------------+-------------------+\n",
      "|count(timestamp)|avg(timestamp)|     min(timestamp)|     max(timestamp)|\n",
      "+----------------+--------------+-------------------+-------------------+\n",
      "|            3236|          null|2017-10-30 09:07:50|2018-06-29 19:37:17|\n",
      "+----------------+--------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.timestamp)\n",
    "H.check_nulls(amz_df, amz_df.timestamp, amz_df.sales_rank)\n",
    "H.basic_stats(amz_df, amz_df.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+--------------------------+\n",
      "|count(sales_rank)|count(DISTINCT sales_rank)|\n",
      "+-----------------+--------------------------+\n",
      "|             3236|                      3216|\n",
      "+-----------------+--------------------------+\n",
      "\n",
      "+---------------------+\n",
      "|Has Null (sales_rank)|\n",
      "+---------------------+\n",
      "|                    0|\n",
      "+---------------------+\n",
      "\n",
      "+-----------------+-----------------+---------------+---------------+\n",
      "|count(sales_rank)|  avg(sales_rank)|min(sales_rank)|max(sales_rank)|\n",
      "+-----------------+-----------------+---------------+---------------+\n",
      "|             3236|208137.0457354759|          25856|         607513|\n",
      "+-----------------+-----------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H.get_basic_counts(amz_df, amz_df.sales_rank)\n",
    "H.check_nulls(amz_df, amz_df.sales_rank, amz_df.timestamp)\n",
    "H.basic_stats(amz_df, amz_df.sales_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}